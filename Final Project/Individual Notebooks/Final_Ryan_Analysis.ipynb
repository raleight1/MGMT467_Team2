{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMnrNE7MkU/9quKdT/Ogjyg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raleight1/MGMT467_Team2/blob/main/Final%20Project/Individual%20Notebooks/Final_Ryan_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# Redefine constants (as they were not preserved in the previous execution context)\n",
        "PROJECT_ID = \"mgmt467-project\"\n",
        "DATASET_ID = \"GymDB\"\n",
        "MODEL_NAME = \"churn_prediction_model\"\n",
        "\n",
        "bq = bigquery.Client(project=PROJECT_ID)\n",
        "\n",
        "# Re-authenticate to ensure fresh credentials\n",
        "auth.authenticate_user()\n",
        "print(\"✅ Re-authenticated to Google Cloud\")\n",
        "\n",
        "evaluation_query = f\"\"\"\n",
        "SELECT\n",
        "  *\n",
        "FROM\n",
        "  ML.EVALUATE(MODEL `{PROJECT_ID}.{DATASET_ID}.{MODEL_NAME}`)\n",
        "\"\"\"\n",
        "\n",
        "print(\"Running model evaluation query...\")\n",
        "eval_result = bq.query(evaluation_query).result().to_dataframe()\n",
        "\n",
        "feature_importance_query = f\"\"\"\n",
        "SELECT\n",
        "  * EXCEPT(category_weights)\n",
        "FROM\n",
        "  ML.WEIGHTS(MODEL `{PROJECT_ID}.{DATASET_ID}.{MODEL_NAME}`)\n",
        "ORDER BY\n",
        "  ABS(weight) DESC\n",
        "\"\"\"\n",
        "\n",
        "print(\"Running feature importance query...\")\n",
        "feature_importance_result = bq.query(feature_importance_query).result().to_dataframe()\n",
        "\n",
        "model_metrics = eval_result.iloc[0]\n",
        "feature_importances = feature_importance_result.copy()\n",
        "\n",
        "# Identify top influential features (excluding intercept)\n",
        "top_features = feature_importances[feature_importances['processed_input'] != '__INTERCEPT__'] \\\n",
        "    .sort_values(by='weight', key=abs, ascending=False)\n",
        "\n",
        "# Extract weather-related features\n",
        "weather_features = top_features[\n",
        "    top_features['processed_input'].isin([\n",
        "        'avg_daily_temperature_c',\n",
        "        'avg_daily_wind_speed_kph',\n",
        "        'avg_daily_relative_humidity',\n",
        "        'day_proportion'\n",
        "    ])\n",
        "]\n",
        "\n",
        "print(\"Model metrics:\")\n",
        "print(model_metrics)\n",
        "print(\"\\nTop features (excluding intercept) by absolute weight:\")\n",
        "print(top_features)\n",
        "print(\"\\nWeather-related feature importances:\")\n",
        "print(weather_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eox9NtB1hKgD",
        "outputId": "21028e10-deba-4ece-ed51-91217675b444"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Re-authenticated to Google Cloud\n",
            "Running model evaluation query...\n",
            "Running feature importance query...\n",
            "Model metrics:\n",
            "precision    1.000000\n",
            "recall       0.025641\n",
            "accuracy     0.746667\n",
            "f1_score     0.050000\n",
            "log_loss     0.554323\n",
            "roc_auc      0.595709\n",
            "Name: 0, dtype: float64\n",
            "\n",
            "Top features (excluding intercept) by absolute weight:\n",
            "               processed_input    weight\n",
            "1      avg_daily_temperature_c -0.061587\n",
            "2                          Age  0.012526\n",
            "3     avg_daily_wind_speed_kph -0.002902\n",
            "4  avg_daily_relative_humidity -0.001968\n",
            "5                  Tenure_Days -0.000028\n",
            "6               day_proportion  0.000000\n",
            "7                       Gender       NaN\n",
            "8              Membership_Type       NaN\n",
            "\n",
            "Weather-related feature importances:\n",
            "               processed_input    weight\n",
            "1      avg_daily_temperature_c -0.061587\n",
            "3     avg_daily_wind_speed_kph -0.002902\n",
            "4  avg_daily_relative_humidity -0.001968\n",
            "6               day_proportion  0.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a comprehensive DIVE analysis for the trained BQML churn prediction model, including a 'Data' section summarizing the GymData_Curated and Weather_Raw_Streaming datasets and features, an 'Insights' section detailing key findings from ML.EVALUATE and ML.WEIGHTS with a focus on weather features, and an 'Evaluation & Next Steps' section outlining model performance, limitations (e.g., low recall), and future improvements. Conclude with one substantive question the model can address.\n"
      ],
      "metadata": {
        "id": "JtcP3GUkhMFR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "985dda4b"
      },
      "source": [
        "# Task\n",
        "Create a comprehensive DIVE analysis for the `churn_prediction_model` in the `GymDB` dataset. The analysis should include:\n",
        "*   A 'Data' section summarizing the `GymData_Curated` and `Weather_Raw_Streaming` datasets and the features they contribute to the model.\n",
        "*   An 'Insights' section detailing key findings from the `ML.EVALUATE` results (`model_metrics` and `eval_result`), including metrics like precision, recall, accuracy, and ROC AUC. This section should also analyze the `ML.WEIGHTS` results (`feature_importance_result`, `top_features`, and `weather_features`), highlighting overall influential features and specifically focusing on the importance and impact of weather-related features.\n",
        "*   An 'Evaluation & Next Steps' section assessing the model's overall performance, discussing its limitations (e.g., the observed low recall), and suggesting concrete future improvements.\n",
        "*   Conclude with one substantive question that the churn prediction model can effectively address.\n",
        "Integrate all generated sections into a comprehensive DIVE analysis document."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4a0e43a"
      },
      "source": [
        "## Data Section: Summarize Datasets and Features\n",
        "\n",
        "### Subtask:\n",
        "Create the 'Data' section of the DIVE analysis, summarizing the `GymData_Curated` and `Weather_Raw_Streaming` datasets and the features they contribute to the `churn_prediction_model`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7a98547"
      },
      "source": [
        "## Data\n",
        "\n",
        "This section describes the datasets used to train the churn prediction model and the features extracted from them.\n",
        "\n",
        "### GymData_Curated Dataset\n",
        "This dataset provides information about individual gym members and their membership details. The features contributed by this dataset to the model include:\n",
        "\n",
        "*   `Age`: Represents the age of the gym member, which can influence their likelihood of churning.\n",
        "*   `Tenure_Days`: Indicates the duration, in days, that a member has been subscribed to the gym. Longer tenure might correlate with lower churn rates.\n",
        "*   `Gender`: The gender of the gym member, potentially revealing different churn patterns across demographics.\n",
        "*   `Membership_Type`: The type of membership held by the member (e.g., monthly, annual, premium), which could be a significant factor in predicting churn due to varying commitment levels or benefits.\n",
        "\n",
        "### Weather_Raw_Streaming Dataset\n",
        "This dataset contains real-time and historical weather information, which has been integrated to analyze its impact on gym member churn. The weather-related features used in the model are:\n",
        "\n",
        "*   `avg_daily_temperature_c`: The average daily temperature in Celsius. Extreme temperatures (hot or cold) might deter members from visiting the gym.\n",
        "*   `avg_daily_wind_speed_kph`: The average daily wind speed in kilometers per hour. High winds could make travel to the gym less appealing.\n",
        "*   `avg_daily_relative_humidity`: The average daily relative humidity. High humidity can affect comfort levels for outdoor activities or travel.\n",
        "*   `day_proportion`: A feature likely representing the proportion of daylight or a categorical representation of the time of day, which could influence when members are most likely to visit or churn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8276db30"
      },
      "source": [
        "## Insights Section: Model Evaluation and Feature Importance\n",
        "\n",
        "### Subtask:\n",
        "Develop the 'Insights' section of the DIVE analysis, detailing key findings from the ML.EVALUATE and ML.WEIGHTS results, with a focus on overall influential features and specifically on weather-related features.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12dea56a"
      },
      "source": [
        "## Insights\n",
        "\n",
        "### Model Evaluation Metrics\n",
        "\n",
        "The model's performance was evaluated using standard classification metrics. Here are the key findings:\n",
        "\n",
        "*   **Precision**: `1.00` - This indicates that when the model predicts a customer will churn, it is always correct. This is a very high precision, suggesting that false positives (predicting churn when a customer does not churn) are very low or non-existent.\n",
        "*   **Recall**: `0.0256` - This metric is quite low, meaning the model only identified a very small percentage (about 2.56%) of the actual churners. While it's accurate when it predicts churn, it misses a significant number of customers who *do* churn.\n",
        "*   **Accuracy**: `0.7467` - The overall accuracy of the model is approximately 74.67%. This represents the proportion of total predictions that were correct (both churners and non-churners).\n",
        "*   **F1-Score**: `0.0500` - The F1-score is the harmonic mean of precision and recall. A low F1-score indicates an imbalance between precision and recall, as seen with our very high precision but very low recall.\n",
        "*   **Log Loss**: `0.5543` - Log loss is a measure of the uncertainty of the predictions. Lower values are better. A log loss of 0.5543 suggests there is still a notable amount of uncertainty in the model's predictions.\n",
        "*   **ROC AUC**: `0.5957` - The Area Under the Receiver Operating Characteristic Curve (ROC AUC) measures the model's ability to distinguish between churners and non-churners. A value of 0.5957 is slightly better than random guessing (0.5), but it indicates the model has limited discriminatory power.\n",
        "\n",
        "**Summary**: The model exhibits extremely high precision, meaning its positive predictions are very reliable. However, its very low recall suggests it struggles to identify most of the actual churn cases. This behavior might be due to an imbalanced dataset where churn events are rare, leading the model to be conservative in its churn predictions. The moderate accuracy and low ROC AUC further suggest that while the model is precise, it's not very robust in capturing the overall churn phenomenon.\n",
        "\n",
        "### Feature Importance\n",
        "\n",
        "Feature importance was determined by the absolute weights assigned to each feature by the model. The weights indicate the strength and direction of a feature's influence on the likelihood of churn.\n",
        "\n",
        "**Overall Most Influential Features (excluding intercept) by Absolute Weight:**\n",
        "\n",
        "*   **avg_daily_temperature_c** (weight: `-0.061587`): This is the most influential feature by a significant margin. The negative weight indicates an inverse relationship with churn; as the average daily temperature increases, the likelihood of customer churn decreases. This might suggest that people are less likely to cancel gym memberships in warmer weather, perhaps due to increased outdoor activity or motivation.\n",
        "*   **Age** (weight: `0.012526`): With a positive weight, an increase in age is associated with a higher likelihood of churn. This could imply that older members are more prone to churning, possibly due to changing fitness needs or activity levels.\n",
        "*   **avg_daily_wind_speed_kph** (weight: `-0.002902`): The negative weight suggests that higher average daily wind speed slightly decreases the likelihood of churn. This influence is much smaller than temperature.\n",
        "\n",
        "Other features like `avg_daily_relative_humidity`, `Tenure_Days`, and `day_proportion` have smaller absolute weights, indicating a lesser impact on churn predictions.\n",
        "\n",
        "#### Weather-Related Feature Importances\n",
        "\n",
        "Focusing specifically on weather-related features:\n",
        "\n",
        "*   **avg_daily_temperature_c** (weight: `-0.061587`): As previously noted, this feature has the strongest influence among all features. A higher average daily temperature significantly *reduces* the probability of churn.\n",
        "*   **avg_daily_wind_speed_kph** (weight: `-0.002902`): This feature has a minor negative impact on churn. Higher wind speeds are associated with a very slight decrease in churn probability.\n",
        "*   **avg_daily_relative_humidity** (weight: `-0.001968`): Similarly, higher average daily relative humidity is associated with a very slight decrease in churn probability, though its impact is minimal.\n",
        "*   **day_proportion** (weight: `0.000000`): This feature has a weight of 0, indicating it had virtually no influence on the churn prediction in this model. It's possible that this feature was deemed irrelevant or had no predictive power by the model.\n",
        "\n",
        "**Features with NaN Weights**: Features such as `Gender` and `Membership_Type` show `NaN` weights. This typically occurs for categorical features when the model (specifically, BigQuery ML's linear/logistic regression models) determines that these features have no significant statistical relationship to the target variable after one-hot encoding or when all categories have been dropped due to insufficient variance or correlation, or if they were effectively excluded during model training due to their lack of predictive power. In simpler terms, these features were not found to be useful in predicting churn by the current model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05ca0111"
      },
      "source": [
        "## Insights\n",
        "\n",
        "### Model Evaluation Metrics\n",
        "\n",
        "The model's performance was evaluated using standard classification metrics. Here are the key findings:\n",
        "\n",
        "*   **Precision**: `1.00` - This indicates that when the model predicts a customer will churn, it is always correct. This is a very high precision, suggesting that false positives (predicting churn when a customer does not churn) are very low or non-existent.\n",
        "*   **Recall**: `0.0256` - This metric is quite low, meaning the model only identified a very small percentage (about 2.56%) of the actual churners. While it's accurate when it predicts churn, it misses a significant number of customers who *do* churn.\n",
        "*   **Accuracy**: `0.7467` - The overall accuracy of the model is approximately 74.67%. This represents the proportion of total predictions that were correct (both churners and non-churners).\n",
        "*   **F1-Score**: `0.0500` - The F1-score is the harmonic mean of precision and recall. A low F1-score indicates an imbalance between precision and recall, as seen with our very high precision but very low recall.\n",
        "*   **Log Loss**: `0.5543` - Log loss is a measure of the uncertainty of the predictions. Lower values are better. A log loss of 0.5543 suggests there is still a notable amount of uncertainty in the model's predictions.\n",
        "*   **ROC AUC**: `0.5957` - The Area Under the Receiver Operating Characteristic Curve (ROC AUC) measures the model's ability to distinguish between churners and non-churners. A value of 0.5957 is slightly better than random guessing (0.5), but it indicates the model has limited discriminatory power.\n",
        "\n",
        "**Summary**: The model exhibits extremely high precision, meaning its positive predictions are very reliable. However, its very low recall suggests it struggles to identify most of the actual churn cases. This behavior might be due to an imbalanced dataset where churn events are rare, leading the model to be conservative in its churn predictions. The moderate accuracy and low ROC AUC further suggest that while the model is precise, it's not very robust in capturing the overall churn phenomenon.\n",
        "\n",
        "### Feature Importance\n",
        "\n",
        "Feature importance was determined by the absolute weights assigned to each feature by the model. The weights indicate the strength and direction of a feature's influence on the likelihood of churn.\n",
        "\n",
        "**Overall Most Influential Features (excluding intercept) by Absolute Weight:**\n",
        "\n",
        "*   **avg_daily_temperature_c** (weight: `-0.061587`): This is the most influential feature by a significant margin. The negative weight indicates an inverse relationship with churn; as the average daily temperature increases, the likelihood of customer churn decreases. This might suggest that people are less likely to cancel gym memberships in warmer weather, perhaps due to increased outdoor activity or motivation.\n",
        "*   **Age** (weight: `0.012526`): With a positive weight, an increase in age is associated with a higher likelihood of churn. This could imply that older members are more prone to churning, possibly due to changing fitness needs or activity levels.\n",
        "*   **avg_daily_wind_speed_kph** (weight: `-0.002902`): The negative weight suggests that higher average daily wind speed slightly decreases the likelihood of churn. This influence is much smaller than temperature.\n",
        "\n",
        "Other features like `avg_daily_relative_humidity`, `Tenure_Days`, and `day_proportion` have smaller absolute weights, indicating a lesser impact on churn predictions.\n",
        "\n",
        "#### Weather-Related Feature Importances\n",
        "\n",
        "Focusing specifically on weather-related features:\n",
        "\n",
        "*   **avg_daily_temperature_c** (weight: `-0.061587`): As previously noted, this feature has the strongest influence among all features. A higher average daily temperature significantly *reduces* the probability of churn.\n",
        "*   **avg_daily_wind_speed_kph** (weight: `-0.002902`): This feature has a minor negative impact on churn. Higher wind speeds are associated with a very slight decrease in churn probability.\n",
        "*   **avg_daily_relative_humidity** (weight: `-0.001968`): Similarly, higher average daily relative humidity is associated with a very slight decrease in churn probability, though its impact is minimal.\n",
        "*   **day_proportion** (weight: `0.000000`): This feature has a weight of 0, indicating it had virtually no influence on the churn prediction in this model. It's possible that this feature was deemed irrelevant or had no predictive power by the model.\n",
        "\n",
        "**Features with NaN Weights**: Features such as `Gender` and `Membership_Type` show `NaN` weights. This typically occurs for categorical features when the model (specifically, BigQuery ML's linear/logistic regression models) determines that these features have no significant statistical relationship to the target variable after one-hot encoding or when all categories have been dropped due to insufficient variance or correlation, or if they were effectively excluded during model training due to their lack of predictive power. In simpler terms, these features were not found to be useful in predicting churn by the current model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43337fda"
      },
      "source": [
        "## Evaluation & Next Steps Section: Performance, Limitations, and Improvements\n",
        "\n",
        "### Subtask:\n",
        "Construct the 'Evaluation & Next Steps' section of the DIVE analysis, including an assessment of the model's overall performance, a discussion of its limitations (e.g., the observed low recall), and concrete suggestions for future improvements to address these limitations and enhance the model.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2731a3ea"
      },
      "source": [
        "## Evaluation & Next Steps\n",
        "\n",
        "### Model Performance Assessment\n",
        "The `churn_prediction_model` demonstrates a mixed performance profile. It achieves a perfect `precision` of `1.00`, indicating that when the model predicts a customer will churn, it is always correct. This is a strong point for scenarios where false positives are costly. However, this comes at the significant cost of an extremely low `recall` of `0.0256`. This means the model only identifies about 2.56% of actual churners. The `accuracy` is `0.7467`, which appears decent but can be misleading in imbalanced datasets, as it might primarily reflect the model's ability to correctly classify the majority non-churning class. The `f1_score` is `0.0500`, a harmonic mean of precision and recall, which is very low due to the poor recall. The `roc_auc` score is `0.5957`, suggesting that the model has some discriminatory power, but it's only slightly better than random guessing (0.5).\n",
        "\n",
        "### Limitations\n",
        "The primary limitation of the current model is its very low `recall`. While its perfect precision means no false positives, the model fails to identify the vast majority of customers who actually churn. This means that if the goal is to proactively intervene with potential churners, this model would miss almost all of them, rendering it largely ineffective for retention strategies. Other limitations include:\n",
        "\n",
        "*   **Moderate `ROC AUC`**: A score of `0.5957` suggests limited ability to distinguish between churning and non-churning customers.\n",
        "*   **Unutilized Categorical Features**: The `NaN` weights for `Gender` and `Membership_Type` indicate these potentially important features were not effectively utilized in the model. This could be due to issues in data preprocessing, feature encoding, or a lack of variance within these features that prevents the model from learning meaningful weights.\n",
        "\n",
        "### Future Improvements\n",
        "To address the identified limitations and enhance the model's performance, especially its ability to detect churners, the following improvements are suggested:\n",
        "\n",
        "*   **Addressing Data Imbalance**: The extremely low recall strongly suggests a severe class imbalance problem (likely many more non-churners than churners). Techniques to mitigate this should be explored:\n",
        "    *   **Oversampling** the minority class (churners) using methods like `SMOTE`.\n",
        "    *   **Undersampling** the majority class (non-churners).\n",
        "    *   Adjusting **class weights** during model training to penalize misclassifications of the minority class more heavily.\n",
        "*   **Feature Engineering**: Explore creating new features or refining existing ones to provide the model with more predictive power:\n",
        "    *   **Interaction terms** between existing features.\n",
        "    *   **Polynomial features** for non-linear relationships.\n",
        "    *   Incorporating more granular **membership activity data** (e.g., frequency of visits, types of classes attended, recent attendance trends).\n",
        "*   **Exploring Different Model Architectures**: Linear models like logistic regression (which BQML often uses for classification) might not be sufficient for complex churn prediction. Consider alternative machine learning algorithms that can handle imbalanced data better or capture more complex relationships:\n",
        "    *   **Gradient Boosting Machines** (e.g., XGBoost, LightGBM).\n",
        "    *   **Neural Networks**.\n",
        "*   **Investigating Current Features**: A detailed investigation into why `Gender` and `Membership_Type` resulted in `NaN` weights is crucial. This could involve:\n",
        "    *   Checking for **data quality issues**.\n",
        "    *   Experimenting with different **encoding strategies** (e.g., one-hot encoding for categorical features).\n",
        "    *   Verifying if these features truly have predictive power in the dataset.\n",
        "*   **Business Goal Alignment**: Re-evaluate the model's objective based on business needs. If identifying as many churners as possible is critical, even with a slightly higher false positive rate, then optimizing for `recall` or `F1-score` over `precision` would be more appropriate. If the goal is highly confident predictions for a targeted marketing campaign, the current high precision might be desirable, but the low recall would still limit its overall impact."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b81a948"
      },
      "source": [
        "\n",
        "\n",
        "**Substantive Question:** Given the significant negative association between average daily temperature and churn, coupled with the influence of member age, and the model's high precision in identifying a subset of churners, how can the gym proactively utilize weather forecasts and member age data to target high-risk demographics with personalized retention incentives during predicted periods of unfavorable weather conditions?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa866712"
      },
      "source": [
        "## Propose Dashboard Integration\n",
        "\n",
        "### Subtask:\n",
        "Outline how the generated insights and interactive Plotly visualization could be integrated into a dashboard section, explaining their influence and value for a larger reporting context.\n",
        "\n",
        "### Dashboard Integration\n",
        "The interactive Plotly visualization of feature importances, along with the model evaluation metrics, can be integrated into a dedicated 'Churn Prediction Model Performance' dashboard. This dashboard would serve as a central hub for stakeholders to monitor the model's effectiveness and understand the driving factors behind churn.\n",
        "\n",
        "**Proposed Dashboard Section: 'Churn Driver Analysis'**\n",
        "\n",
        "1.  **Interactive Feature Importance Chart**: The Plotly bar chart displaying `ML.WEIGHTS` results (`feature_importances`) should be a key component. This allows users to:\n",
        "    *   **Visually identify top churn drivers**: Quickly see which features (e.g., `avg_daily_temperature_c`, `Age`) have the most significant impact.\n",
        "    *   **Understand direction of influence**: The positive/negative weights provide immediate insight into how each feature affects churn probability.\n",
        "    *   **Drill down into specifics**: Hover-over functionality can display exact weight values and feature names for detailed understanding.\n",
        "\n",
        "2.  **Model Performance Metrics (Overview)**: Key metrics from `ML.EVALUATE` (`precision`, `recall`, `accuracy`, `roc_auc`, `f1_score`) should be displayed prominently, perhaps as gauge charts or scorecards. This provides a quick snapshot of the model's overall health.\n",
        "\n",
        "3.  **Weather Impact Trends**: Given the strong influence of `avg_daily_temperature_c` and other weather features, a dedicated section showing historical weather trends overlaid with churn rates could be valuable. This could be another interactive plot, allowing filtering by location or time period.\n",
        "\n",
        "**Value for Stakeholders**: This dashboard section would empower business users to:\n",
        "*   **Prioritize interventions**: Focus on influencing the most impactful churn drivers.\n",
        "*   **Tailor retention strategies**: Develop weather-sensitive campaigns or age-specific offers.\n",
        "*   **Monitor model stability**: Track how feature importances or model performance metrics change over time, indicating potential data shifts or model degradation.\n",
        "\n",
        "**Link to Dashboard Section**: This specific 'Churn Driver Analysis' section would be a crucial part of a broader 'Customer Retention Dashboard', providing actionable insights derived directly from the model's mechanics."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "2d969848",
        "outputId": "b0141a4f-0f56-416a-c0b9-164e9a4d2b55"
      },
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Create an interactive bar chart for feature importances\n",
        "fig = px.bar(\n",
        "    feature_importances.sort_values(by='weight', key=abs, ascending=False),\n",
        "    x='processed_input',\n",
        "    y='weight',\n",
        "    title='Interactive Feature Importance for Churn Prediction Model',\n",
        "    labels={'processed_input': 'Feature', 'weight': 'Weight'},\n",
        "    hover_data=['processed_input', 'weight']\n",
        ")\n",
        "\n",
        "fig.update_layout(\n",
        "    xaxis_title='Feature',\n",
        "    yaxis_title='Weight (Impact on Churn)',\n",
        "    xaxis_tickangle=-45,\n",
        "    height=500,\n",
        "    width=800\n",
        ")\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"62bdfefc-8703-4cc0-a51a-6d99f1e81a26\" class=\"plotly-graph-div\" style=\"height:500px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"62bdfefc-8703-4cc0-a51a-6d99f1e81a26\")) {                    Plotly.newPlot(                        \"62bdfefc-8703-4cc0-a51a-6d99f1e81a26\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Feature=%{x}\\u003cbr\\u003eWeight=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"__INTERCEPT__\",\"avg_daily_temperature_c\",\"Age\",\"avg_daily_wind_speed_kph\",\"avg_daily_relative_humidity\",\"Tenure_Days\",\"day_proportion\",\"Gender\",\"Membership_Type\"],\"xaxis\":\"x\",\"y\":[-0.257382205683765,-0.061587047191287325,0.012526287694026386,-0.0029015534765949,-0.001967538669100704,-0.00002780816933073177,0.0,null,null],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Feature\"},\"tickangle\":-45},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Weight (Impact on Churn)\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Interactive Feature Importance for Churn Prediction Model\"},\"barmode\":\"relative\",\"height\":500,\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('62bdfefc-8703-4cc0-a51a-6d99f1e81a26');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "089bda2d"
      },
      "source": [
        "### Interactive Plotly Visualization: Feature Importance\n",
        "\n",
        "This interactive bar chart illustrates the absolute weights of each feature in the churn prediction model. Features with larger absolute weights have a greater impact on the model's prediction. The chart allows for easy comparison of feature influence and hovering over bars reveals exact weight values.\n",
        "\n",
        "Key observations from this visualization reinforce the earlier findings: `avg_daily_temperature_c` stands out as the most influential feature, followed by `Age`. The relative impact of other features like `avg_daily_wind_speed_kph` and `avg_daily_relative_humidity` is also clearly visible."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61477197"
      },
      "source": [
        "## Compile DIVE Analysis with Prompt Logs\n",
        "\n",
        "### Subtask:\n",
        "Integrate all the generated sections ('Data', 'Insights', 'Evaluation & Next Steps', and the substantive question) into a comprehensive DIVE analysis document.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2241a0e1"
      },
      "source": [
        "## DIVE Analysis: Gym Churn Prediction Model\n",
        "\n",
        "This document presents a comprehensive DIVE analysis for the BigQuery ML churn prediction model, integrating data descriptions, key insights from model evaluation and feature importance, and outlining next steps for improvement.\n",
        "\n",
        "### 1. Data\n",
        "\n",
        "The churn prediction model leverages two primary datasets:\n",
        "\n",
        "*   **`GymDB.GymData_Curated`**: This dataset likely contains customer-specific information relevant to gym membership, such as `Age`, `Tenure_Days`, `Gender`, and `Membership_Type`.\n",
        "*   **`GymDB.Weather_Raw_Streaming`**: This dataset is integrated to provide environmental context, including features like `avg_daily_temperature_c`, `avg_daily_wind_speed_kph`, `avg_daily_relative_humidity`, and `day_proportion`.\n",
        "\n",
        "These datasets are combined to provide a holistic view of factors influencing customer churn for the model named `churn_prediction_model` within the `mgmt467-project`.\n",
        "\n",
        "### 2. Insights\n",
        "\n",
        "**Model Evaluation (`ML.EVALUATE`)**: The initial evaluation of the model (`ML.EVALUATE`) provides the following key metrics:\n",
        "\n",
        "```\n",
        "precision    1.000000\n",
        "recall       0.025641\n",
        "accuracy     0.746667\n",
        "f1_score     0.050000\n",
        "log_loss     0.554323\n",
        "roc_auc      0.595709\n",
        "```\n",
        "\n",
        "**Feature Importance (`ML.WEIGHTS`)**: Analyzing the feature weights reveals the most influential factors in predicting churn:\n",
        "\n",
        "| processed_input             | weight      |\n",
        "| :-------------------------- | :---------- |\n",
        "| `avg_daily_temperature_c`   | -0.061587   |\n",
        "| `Age`                       | 0.012526    |\n",
        "| `avg_daily_wind_speed_kph`  | -0.002902   |\n",
        "| `avg_daily_relative_humidity` | -0.001968   |\n",
        "| `Tenure_Days`               | -0.000028   |\n",
        "| `day_proportion`            | 0.000000    |\n",
        "| `Gender`                    | NaN         |\n",
        "| `Membership_Type`           | NaN         |\n",
        "\n",
        "**Key Findings**:\n",
        "*   **Temperature as a Strong Predictor**: `avg_daily_temperature_c` is the most influential feature by absolute weight, indicating a strong negative correlation with churn (lower temperatures associated with higher churn, or vice-versa depending on the true meaning of the negative weight).\n",
        "*   **Age's Influence**: `Age` also shows a notable positive weight, suggesting older members might be slightly more prone to churn or that it's a factor in churn prediction.\n",
        "*   **Weather Impact**: Other weather-related features like `avg_daily_wind_speed_kph` and `avg_daily_relative_humidity` have smaller but present weights, suggesting that weather conditions collectively play a role in churn behavior. `day_proportion` has a weight of 0, implying it had no predictive power in this model.\n",
        "*   **Categorical Features**: `Gender` and `Membership_Type` show `NaN` weights, which might indicate that they were either dropped during preprocessing, had zero variance, or their categories did not contribute meaningfully to the linear model.\n",
        "\n",
        "### 3. Evaluation & Next Steps\n",
        "\n",
        "**Model Performance**: The model exhibits a very high precision (1.0), meaning that when it predicts churn, it is always correct. However, its recall is extremely low (0.0256), indicating that it misses most of the actual churners. The accuracy is moderate (0.746), but given the imbalanced recall, this might be misleading. The `f1_score` (0.05) and `roc_auc` (0.595) further confirm that while the model is precise in its few positive predictions, it is generally poor at identifying churners.\n",
        "\n",
        "**Limitations**: The most significant limitation is the very low recall. This suggests the model is highly conservative in predicting churn, likely due to class imbalance or insufficient predictive power for the positive class. The `NaN` weights for categorical features also suggest potential issues with how these features were handled or their lack of predictive value.\n",
        "\n",
        "**Future Improvements**:\n",
        "*   **Address Class Imbalance**: Techniques like oversampling the minority class (churners), undersampling the majority class (non-churners), or using cost-sensitive learning should be explored.\n",
        "*   **Feature Engineering**: Revisit and potentially enhance features from `Gender` and `Membership_Type` or explore interaction terms.\n",
        "*   **Model Selection**: Consider alternative models better suited for imbalanced datasets or non-linear relationships, such as Gradient Boosting Machines (XGBoost, LightGBM) or neural networks.\n",
        "*   **Hyperparameter Tuning**: Optimize the model's hyperparameters to improve recall without severely sacrificing precision.\n",
        "\n",
        "### 4. Substantive Question\n",
        "\n",
        "Given the observed influence of weather on churn, **'How does extreme weather (e.g., unusually hot/cold days, high winds) impact a customer's likelihood of churning within a specific time frame, and what targeted interventions could mitigate this effect?'**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f52a4cb7"
      },
      "source": [
        "## Final Task\n",
        "\n",
        "### Subtask:\n",
        "Review the complete DIVE analysis to ensure all requirements are met, including the summary of datasets, detailed insights from model evaluation and feature importance, discussion of limitations and improvements, and the substantive question.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5c4e4af"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **Data Sources and Features**: The churn prediction model utilized two datasets:\n",
        "    *   `GymData_Curated`: Contributed member-specific features such as `Age`, `Tenure_Days`, `Gender`, and `Membership_Type`.\n",
        "    *   `Weather_Raw_Streaming`: Provided environmental context through features like `avg_daily_temperature_c`, `avg_daily_wind_speed_kph`, `avg_daily_relative_humidity`, and `day_proportion`.\n",
        "*   **Model Performance Overview**: The model demonstrated a mixed performance profile with a perfect `precision` of `1.00`, but an extremely low `recall` of `0.0256`. The overall `accuracy` was `0.7467`, the `f1_score` was `0.0500`, `log_loss` was `0.5543`, and `roc_auc` was `0.5957`.\n",
        "*   **High Precision, Low Recall**: While the model is always correct when it predicts a customer will churn, it only identifies approximately 2.56% of actual churners, indicating it misses the vast majority of churn events.\n",
        "*   **Feature Importance**:\n",
        "    *   `avg_daily_temperature_c` was identified as the most influential feature (weight: `-0.061587`), showing a strong inverse relationship with churn (higher temperatures associated with lower churn probability).\n",
        "    *   `Age` was also a notable influencer (weight: `0.012526`), suggesting older members might be more prone to churn.\n",
        "    *   Other weather features like `avg_daily_wind_speed_kph` (weight: `-0.002902`) and `avg_daily_relative_humidity` (weight: `-0.001968`) had minor impacts.\n",
        "    *   `day_proportion` had no observed influence (weight: `0.000000`).\n",
        "*   **Unutilized Categorical Features**: `Gender` and `Membership_Type` exhibited `NaN` weights, implying they were not effectively utilized by the model, potentially due to preprocessing issues, lack of variance, or insufficient predictive power.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   **Address Class Imbalance**: The model's low recall is a critical limitation for proactive churn intervention. Future efforts should focus on addressing the likely class imbalance using techniques such as oversampling (e.g., SMOTE), undersampling, or adjusting class weights during training.\n",
        "*   **Strategic Interventions and Further Investigation**: The gym should investigate how to proactively utilize weather forecasts and member age data to target high-risk demographics with personalized retention incentives, particularly during predicted periods of unfavorable weather conditions. For example, \"How does extreme weather (e.g., unusually hot/cold days, high winds) impact a customer's likelihood of churning within a specific time frame, and what targeted interventions could mitigate this effect?\"\n"
      ]
    }
  ]
}